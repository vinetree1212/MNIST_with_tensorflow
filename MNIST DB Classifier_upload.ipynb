{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST DB Classifier\n",
    "\n",
    "###18.11.23\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "print('Hello World') #문자 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'jupyter_tfbook' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Jpub/TensorflowDeeplearning jupyter_tfbook\n",
    "    #github로부터 파일을 clone해온다. \n",
    "    #이후 파일목록을 확인하면 새로운 폴더가 추가되어 있는것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SoftMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 출력 이전layer에 항상 softmax 가 붙는다\n",
    "# 총합이 1, 각 class에 해당하는 확률을 배당하는 함수이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Dataset 받아오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #numpy library import\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-d651cc53d7d8>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\James\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\James\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\James\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\James\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\James\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = mnist.train.next_batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#추출한 데이터는 이미지 데이터와 라벨 데이터로 나뉘며 \n",
    "#여기선 각각을 변수 images와 label로 저장한다.\n",
    "\n",
    "#각각 10개의 데이터를 포함하는 리스트로 되어잇다.\n",
    "#추출한 이미지는 28x28 = 784 픽셀에 대해 \n",
    "#각각의 농도를 나타내는 수치를 ㄴ열한 list이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.16470589 0.40000004 0.54509807\n",
      " 0.627451   0.76470596 0.9294118  1.         0.9960785  0.24313727\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.1137255\n",
      " 0.79215693 0.9568628  0.9960785  0.9960785  0.9960785  0.9960785\n",
      " 0.9960785  0.9960785  0.9960785  0.5137255  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.49803925 0.9960785  0.9960785\n",
      " 0.9960785  0.9960785  0.9960785  0.9960785  0.9960785  0.9960785\n",
      " 0.9960785  0.6509804  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.7411765  0.9960785  0.9960785  0.9960785  0.9843138\n",
      " 0.5882353  0.33333334 0.33333334 0.8000001  0.9960785  0.5137255\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.21568629\n",
      " 0.4431373  0.34901962 0.07058824 0.07058824 0.         0.\n",
      " 0.48235297 0.9725491  0.9960785  0.44705886 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.0509804  0.4901961  0.9607844  0.9960785\n",
      " 0.50980395 0.02745098 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1254902  0.         0.         0.43137258 0.5647059  0.7019608\n",
      " 0.8980393  0.9960785  0.9960785  0.7607844  0.13333334 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.80392164 0.7803922\n",
      " 0.86666673 0.9960785  0.9960785  0.9960785  0.9960785  0.9960785\n",
      " 0.64705884 0.12156864 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.9607844  0.9960785  0.9960785  0.9960785\n",
      " 0.9960785  0.9960785  0.9960785  0.9960785  0.22352943 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.54901963 0.6784314  0.62352943 0.627451   0.29803923 0.5411765\n",
      " 0.8705883  0.9960785  0.6862745  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.92549026\n",
      " 0.9686275  0.18823531 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.6745098  0.9960785  0.29411766\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.18823531 0.9960785  0.29411766 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.29803923\n",
      " 0.9960785  0.29411766 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.05882353 0.909804   0.9803922  0.2392157\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.11764707\n",
      " 0.7725491  0.34509805 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.14509805 0.3921569  0.5137255\n",
      " 0.86666673 0.9960785  0.8941177  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.2627451  0.9960785  0.8470589\n",
      " 0.         0.         0.14901961 0.22352943 0.20000002 0.3372549\n",
      " 0.47450984 0.89019614 0.9960785  0.9960785  0.9960785  0.6862745\n",
      " 0.23137257 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.2627451  0.9960785  0.9921569  0.9607844  0.9607844\n",
      " 0.97647065 0.9843138  0.9803922  0.9960785  0.9960785  0.9960785\n",
      " 0.9960785  0.9568628  0.28235295 0.03137255 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.13725491\n",
      " 0.90196085 0.9960785  0.9960785  0.9960785  0.9960785  0.9960785\n",
      " 0.9960785  0.80392164 0.74509805 0.6509804  0.46274513 0.14117648\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.18823531 0.77647066\n",
      " 0.9960785  0.6509804  0.62352943 0.62352943 0.5411765  0.13333334\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print (images[0]) #255 크기의 데이터값을 생으로 출력한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 진짜 이미지 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = [8,4]) # 코드 나누면 이미지 안뜸 \n",
    "for c, (image, label) in enumerate(zip(images,labels)):\n",
    "    subplot = fig.add_subplot(2,5,c+1)\n",
    "    subplot.set_xticks([])\n",
    "    subplot.set_yticks([])\n",
    "    subplot.set_title('%d' %np.argmax(label))  #오브젝트 subplot의 imshow메소드로 이미지를 출력한다. \n",
    "    subplot.imshow(image.reshape((28,28)),vmin=0,vmax=1,cmap=plt.cm.gray_r, interpolation=\"nearest\") # 28크기의 이미지로 출력. \n",
    "    #vmin vmax는 농담의 범위이다. # 원래 픽셀간 보정을 통해 이미지를 부드럽게 출력하는데 여기서는 nearest 설정을 통해 비활성화 했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST 구현\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "np.random.seed(20181123)\n",
    "tf.set_random_seed(20181123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filters1 = 32 \n",
    "#1st convolution filter\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None,784])\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "\n",
    "W_conv1 = tf.Variable(tf.truncated_normal([5,5,1,num_filters1], stddev=0.1))\n",
    "h_conv1 = tf.nn.conv2d(x_image,W_conv1,strides=[1,1,1,1],padding='SAME')\n",
    "\n",
    "b_conv1 = tf.Variable(tf.constant(0.1, shape=[num_filters1]))\n",
    "h_conv1_cutoff = tf.nn.relu(h_conv1 + b_conv1)\n",
    "\n",
    "h_pool1 = tf.nn.max_pool(h_conv1_cutoff, ksize=[1,2,2,1], strides=[1,2,2,1],padding='SAME')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filters2 = 64 \n",
    "# 2nd convolution filter\n",
    "\n",
    "W_conv2 = tf.Variable(tf.truncated_normal([5,5,num_filters1,num_filters2], stddev=0.1))\n",
    "\n",
    "h_conv2 = tf.nn.conv2d(h_pool1, W_conv2, strides=[1,1,1,1],padding='SAME')\n",
    "\n",
    "b_conv2 = tf.Variable(tf.constant(0.1,shape=[num_filters2])) # Variable =/= Varialbe\n",
    "h_conv2_cutoff = tf.nn.relu(h_conv2 + b_conv2)\n",
    "\n",
    "h_pool2 = tf.nn.max_pool(h_conv2_cutoff, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_pool2_flat = tf.reshape(h_pool2, [-1,7*7*num_filters2])\n",
    "#전 결합층, dropout(overfit방지), softmax함수 추가한다.\n",
    "#softmax = 총합이 1인 classifier\n",
    "\n",
    "num_units1 = 7*7*num_filters2\n",
    "num_units2 = 1024\n",
    "\n",
    "w2 = tf.Variable(tf.truncated_normal([num_units1, num_units2]))\n",
    "b2 = tf.Variable(tf.constant(0.1, shape=[num_units2]))\n",
    "hidden2 = tf.nn.relu(tf.matmul(h_pool2_flat, w2) + b2)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "hidden2_drop = tf.nn.dropout(hidden2, keep_prob)\n",
    "\n",
    "w0 = tf.Variable(tf.zeros([num_units2,10]))\n",
    "b0 = tf.Variable(tf.zeros([10]))\n",
    "p=tf.nn.softmax(tf.matmul(hidden2_drop,w0)+b0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.placeholder(tf.float32, [None,10])\n",
    "loss = -tf.reduce_sum(t*tf.log(p)) #loss func\n",
    "train_step = tf.train.AdamOptimizer(0.0001).minimize(loss) #트레이닝  크기\n",
    "correct_prediction = tf.equal(tf.argmax(p,1), tf.argmax(t,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) #정답률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#session준비\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "#sess = tf.InteractiveSession.close()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "slice indices must be integers or None or have an __index__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-d62b6d6d47b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             loss_val, acc_val = sess.run([loss,accuracy],\n\u001b[1;32m---> 14\u001b[1;33m                                         feed_dict={x:mnist.test.images[start:end],\n\u001b[0m\u001b[0;32m     15\u001b[0m                                                    \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                                                    keep_prob:1.0})\n",
      "\u001b[1;31mTypeError\u001b[0m: slice indices must be integers or None or have an __index__ method"
     ]
    }
   ],
   "source": [
    "#1회당 50개의 데이터를 사용하는 미니 배치로 파라미터 최적화 실시한다.\n",
    "i=0\n",
    "for _ in range(20000):\n",
    "    i += 1\n",
    "    batch_xs, batch_ts = mnist.train.next_batch(50)\n",
    "    sess.run(train_step, feed_dict = {x:batch_xs, t:batch_ts, keep_prob:0.5})\n",
    "    \n",
    "    if i%500 ==0:\n",
    "        loss_vals, acc_vals = [],[]\n",
    "        for c in range(4):\n",
    "            start = len(mnist.test.labels) /4*c\n",
    "            end = len(mnist.test.labels) / 4*(c+1)\n",
    "            loss_val, acc_val = sess.run([loss,accuracy],\n",
    "                                        feed_dict={x:mnist.test.images[start:end],\n",
    "                                                   t:mnist.test.labels[start:end],\n",
    "                                                   keep_prob:1.0})\n",
    "            loss_vals.append(loss_val)\n",
    "            acc_vals.append(acc_val)\n",
    "        loss_val = np.sum(loss_vals)\n",
    "        acc_val = np.mean(acc_vals)\n",
    "        print('Step: %d, Loss: %f, Accuracy:%f'\n",
    "              %(i,loss_val, acc_val))\n",
    "        saver.save(sess, 'enn_session', global_step=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
